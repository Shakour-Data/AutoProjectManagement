"""
Comprehensive unit tests for autoprojectmanagement/main_modules/progress_reporting/progress_report.py
Generated by AutoProjectManagement testing framework
"""

import pytest
import json
import os
import tempfile
from pathlib import Path
from unittest.mock import patch, mock_open
from autoprojectmanagement.main_modules.progress_reporting.progress_report import (
    ProgressReport, DEFAULT_PROGRESS_PATH, DEFAULT_TASK_DB_PATH, DEFAULT_DASHBOARD_PATH
)

@pytest.fixture
def temp_dir():
    """Fixture for temporary directory."""
    with tempfile.TemporaryDirectory() as tmpdir:
        yield tmpdir

@pytest.fixture
def sample_progress_data():
    """Fixture for sample progress data."""
    return {
        "task1": {
            "commit_count": 5,
            "last_commit_date": "2025-08-14T10:00:00",
            "progress_percent": 100
        },
        "task2": {
            "commit_count": 3,
            "last_commit_date": "2025-08-14T09:00:00",
            "progress_percent": 50
        }
    }

@pytest.fixture
def sample_task_db():
    """Fixture for sample task database."""
    return {
        "task1": {
            "file_path": "src/module1.py",
            "is_milestone": True,
            "description": "Core module implementation"
        },
        "task2": {
            "file_path": "src/module2.py",
            "is_milestone": False,
            "description": "Helper module implementation"
        }
    }

class TestProgressReportFunctionality:
    """Test class for ProgressReport functionality tests (5 tests)"""
    
    def test_progress_report_initialization(self):
        """Test ProgressReport initialization with default parameters."""
        report = ProgressReport()
        assert report.progress_path == DEFAULT_PROGRESS_PATH
        assert report.task_db_path == DEFAULT_TASK_DB_PATH
        assert report.output_path == DEFAULT_DASHBOARD_PATH
    
    def test_progress_report_initialization_custom_paths(self, temp_dir):
        """Test ProgressReport initialization with custom paths."""
        progress_path = os.path.join(temp_dir, "custom_progress.json")
        task_db_path = os.path.join(temp_dir, "custom_task_db.json")
        output_path = os.path.join(temp_dir, "custom_report.md")
        
        report = ProgressReport(progress_path, task_db_path, output_path)
        assert str(report.progress_path) == progress_path
        assert str(report.task_db_path) == task_db_path
        assert str(report.output_path) == output_path
    
    def test_progress_report_load_json(self, temp_dir):
        """Test ProgressReport loading JSON data."""
        json_path = os.path.join(temp_dir, "test_data.json")
        test_data = {"key": "value", "number": 42}
        
        with open(json_path, 'w') as f:
            json.dump(test_data, f)
        
        report = ProgressReport()
        loaded_data = report.load_json(Path(json_path))
        
        assert loaded_data == test_data
    
    def test_progress_report_generate_progress_summary(self, temp_dir, sample_progress_data, sample_task_db):
        """Test ProgressReport generating progress summary."""
        # Create sample files
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        
        with open(progress_path, 'w') as f:
            json.dump(sample_progress_data, f)
        
        with open(task_db_path, 'w') as f:
            json.dump(sample_task_db, f)
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["total_tasks"] == 2
        assert summary["completed_tasks"] == 1
        assert summary["in_progress_tasks"] == 1
        assert summary["pending_tasks"] == 0
        assert summary["completion_rate"] == 50.0
    
    def test_progress_report_generate_markdown_report(self, sample_progress_data, sample_task_db):
        """Test ProgressReport generating markdown report."""
        # Create sample data
        progress_path = "progress.json"
        task_db_path = "task_db.json"
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = {
            'total_tasks': 2,
            'completed_tasks': 1,
            'in_progress_tasks': 1,
            'pending_tasks': 0,
            'completion_rate': 50.0,
            'milestones_achieved': 1,
            'milestone_tasks': [("src/module1.py", "Completed")]
        }
        
        markdown_report = report.generate_markdown_report(summary)
        
        assert "# Project Progress Report" in markdown_report
        assert "Generated on" in markdown_report
        assert "- **Total Tasks**: 2" in markdown_report
        assert "- **Completed Tasks**: 1" in markdown_report
        assert "- **Completion Rate**: 50.0%" in markdown_report

class TestProgressReportEdgeCases:
    """Test class for ProgressReport edge cases (5 tests)"""
    
    def test_progress_report_empty_task_database(self, temp_dir):
        """Test ProgressReport with empty task database."""
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        
        # Create empty files
        with open(progress_path, 'w') as f:
            json.dump({}, f)
        
        with open(task_db_path, 'w') as f:
            json.dump({}, f)
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["total_tasks"] == 0
        assert summary["completed_tasks"] == 0
        assert summary["completion_rate"] == 0.0
    
    def test_progress_report_nonexistent_files(self, temp_dir):
        """Test ProgressReport with nonexistent files."""
        progress_path = os.path.join(temp_dir, "nonexistent_progress.json")
        task_db_path = os.path.join(temp_dir, "nonexistent_task_db.json")
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["total_tasks"] == 0
        assert summary["completed_tasks"] == 0
        assert summary["completion_rate"] == 0.0
    
    def test_progress_report_malformed_json(self, temp_dir):
        """Test ProgressReport with malformed JSON files."""
        progress_path = os.path.join(temp_dir, "malformed_progress.json")
        task_db_path = os.path.join(temp_dir, "malformed_task_db.json")
        
        # Create malformed JSON files
        with open(progress_path, 'w') as f:
            f.write("{ invalid json }")
        
        with open(task_db_path, 'w') as f:
            f.write("{ invalid json }")
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["total_tasks"] == 0
        assert summary["completed_tasks"] == 0
        assert summary["completion_rate"] == 0.0
    
    def test_progress_report_all_tasks_completed(self, temp_dir):
        """Test ProgressReport with all tasks completed."""
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        
        # Create data with all tasks completed
        progress_data = {
            "task1": {"progress_percent": 100},
            "task2": {"progress_percent": 100}
        }
        
        task_db = {
            "task1": {"file_path": "src/module1.py"},
            "task2": {"file_path": "src/module2.py"}
        }
        
        with open(progress_path, 'w') as f:
            json.dump(progress_data, f)
        
        with open(task_db_path, 'w') as f:
            json.dump(task_db, f)
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["total_tasks"] == 2
        assert summary["completed_tasks"] == 2
        assert summary["completion_rate"] == 100.0
    
    def test_progress_report_no_tasks_in_progress(self, temp_dir):
        """Test ProgressReport with no tasks in progress."""
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        
        # Create data with no tasks in progress
        progress_data = {
            "task1": {"progress_percent": 100},
            "task2": {"progress_percent": 0}
        }
        
        task_db = {
            "task1": {"file_path": "src/module1.py"},
            "task2": {"file_path": "src/module2.py"}
        }
        
        with open(progress_path, 'w') as f:
            json.dump(progress_data, f)
        
        with open(task_db_path, 'w') as f:
            json.dump(task_db, f)
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["total_tasks"] == 2
        assert summary["completed_tasks"] == 1
        assert summary["in_progress_tasks"] == 0
        assert summary["pending_tasks"] == 1

class TestProgressReportErrorHandling:
    """Test class for ProgressReport error handling (5 tests)"""
    
    def test_progress_report_invalid_path_types(self):
        """Test ProgressReport with invalid path types."""
        with pytest.raises(ValueError):
            ProgressReport(123, "valid_path", "valid_path")
        
        with pytest.raises(ValueError):
            ProgressReport("valid_path", 123, "valid_path")
        
        with pytest.raises(ValueError):
            ProgressReport("valid_path", "valid_path", 123)
    
    def test_progress_report_file_not_found_error(self, temp_dir):
        """Test ProgressReport handling of file not found errors."""
        nonexistent_path = os.path.join(temp_dir, "nonexistent.json")
        report = ProgressReport(nonexistent_path, nonexistent_path, "")
        
        # Should handle file not found gracefully
        summary = report.generate_progress_summary()
        assert summary["total_tasks"] == 0
        assert summary["completed_tasks"] == 0
    
    def test_progress_report_json_decode_error(self, temp_dir):
        """Test ProgressReport handling of JSON decode errors."""
        malformed_path = os.path.join(temp_dir, "malformed.json")
        
        # Create a malformed JSON file
        with open(malformed_path, 'w') as f:
            f.write("{ invalid json }")
        
        report = ProgressReport(malformed_path, malformed_path, "")
        
        # Should handle JSON decode error gracefully
        summary = report.generate_progress_summary()
        assert summary["total_tasks"] == 0
        assert summary["completed_tasks"] == 0
    
    def test_progress_report_permission_error(self, temp_dir):
        """Test ProgressReport handling of permission errors."""
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        
        # Create files
        with open(progress_path, 'w') as f:
            json.dump({}, f)
        
        with open(task_db_path, 'w') as f:
            json.dump({}, f)
        
        # Make files unreadable
        os.chmod(progress_path, 0o000)
        os.chmod(task_db_path, 0o000)
        
        report = ProgressReport(progress_path, task_db_path, "")
        
        # Should handle permission errors gracefully
        summary = report.generate_progress_summary()
        assert summary["total_tasks"] == 0
        assert summary["completed_tasks"] == 0
    
    def test_progress_report_save_report_permission_error(self, temp_dir):
        """Test ProgressReport handling of permission errors when saving report."""
        # Create a directory with no write permissions
        restricted_dir = os.path.join(temp_dir, "restricted")
        os.makedirs(restricted_dir, mode=0o444)  # Read-only
        
        output_path = os.path.join(restricted_dir, "report.md")
        report = ProgressReport(output_path=output_path)
        
        # Should handle permission errors when saving
        try:
            report.save_report("# Test Report")
            # If we get here, the save succeeded (which might happen on some systems)
            assert True
        except Exception:
            # If we get an exception, that's also acceptable
            assert True

class TestProgressReportIntegration:
    """Test class for ProgressReport integration tests (5 tests)"""
    
    def test_progress_report_complete_workflow(self, temp_dir, sample_progress_data, sample_task_db):
        """Test complete workflow of ProgressReport."""
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        output_path = os.path.join(temp_dir, "report.md")
        
        # Create sample files
        with open(progress_path, 'w') as f:
            json.dump(sample_progress_data, f)
        
        with open(task_db_path, 'w') as f:
            json.dump(sample_task_db, f)
        
        report = ProgressReport(progress_path, task_db_path, output_path)
        report.generate()
        
        # Verify report was created
        assert os.path.exists(output_path)
        
        # Verify report content
        with open(output_path, 'r') as f:
            content = f.read()
        
        assert "# Project Progress Report" in content
        assert "Generated on" in content
    
    def test_progress_report_with_milestones(self, temp_dir):
        """Test ProgressReport with milestone tasks."""
        progress_path = os.path.join(temp_dir, "progress.json")
        task_db_path = os.path.join(temp_dir, "task_db.json")
        
        # Create data with milestones
        progress_data = {
            "milestone_task": {"progress_percent": 100},
            "regular_task": {"progress_percent": 50}
        }
        
        task_db = {
            "milestone_task": {
                "file_path": "src/milestone.py",
                "is_milestone": True
            },
            "regular_task": {
                "file_path": "src/regular.py",
                "is_milestone": False
            }
        }
        
        with open(progress_path, 'w') as f:
            json.dump(progress_data, f)
        
        with open(task_db_path, 'w') as f:
            json.dump(task_db, f)
        
        report = ProgressReport(progress_path, task_db_path, "")
        summary = report.generate_progress_summary()
        
        assert summary["milestones_achieved"] == 1
        assert len(summary["milestone_tasks"]) == 2
    
    def test_progress_report_empty_summary(self):
        """Test ProgressReport with empty summary."""
        report = ProgressReport()
        empty_summary = report._get_empty_summary()
        
        assert empty_summary["total_tasks"] == 0
        assert empty_summary["completed_tasks"] == 0
        assert empty_summary["completion_rate"] == 0.0
        assert empty_summary["milestone_tasks"] == []
    
    def test_progress_report_generate_function(self, temp_dir):
        """Test the generate_report function."""
        # This test is more of a smoke test since the function just creates
        # a ProgressReport instance and calls generate()
        try:
            from autoprojectmanagement.main_modules.progress_reporting.progress_report import generate_report
            # We can't easily test this without mocking the file system
            assert callable(generate_report)
        except Exception:
            # If there's an import error, that's a problem
            assert False, "generate_report function should be importable"
    
    def test_progress_report_end_to_end_with_real_files(self, temp_dir):
        """Test ProgressReport end-to-end with real files."""
        # Create a temporary directory structure that mimics the expected paths
        json_db_dir = os.path.join(temp_dir, "JSonDataBase", "OutPuts")
        os.makedirs(json_db_dir, exist_ok=True)
        
        progress_path = os.path.join(json_db_dir, "commit_progress.json")
        task_db_path = os.path.join(json_db_dir, "commit_task_database.json")
        output_path = os.path.join(json_db_dir, "progress_report.md")
        
        # Create sample data
        progress_data = {
            "task1": {"progress_percent": 75},
            "task2": {"progress_percent": 25}
        }
        
        task_db = {
            "task1": {"file_path": "src/module1.py"},
            "task2": {"file_path": "src/module2.py"}
        }
        
        with open(progress_path, 'w') as f:
            json.dump(progress_data, f)
        
        with open(task_db_path, 'w') as f:
            json.dump(task_db, f)
        
        # Test with custom paths
        report = ProgressReport(progress_path, task_db_path, output_path)
        report.generate()
        
        # Verify the report was created
        assert os.path.exists(output_path)
        
        # Verify content
        with open(output_path, 'r') as f:
            content = f.read()
        
        assert "# Project Progress Report" in content
        assert "- **Total Tasks**: 2" in content

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
