# AutoProjectManagement Monitoring Configuration
# Production Monitoring and Alerting Setup

version: '1.0'
description: Production monitoring configuration for AutoProjectManagement

## Prometheus Configuration
prometheus:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    environment: production
    application: autoprojectmanagement

  scrape_configs:
    - job_name: 'autoprojectmanagement'
      static_configs:
        - targets: ['localhost:8000']
          labels:
            instance: 'autoprojectmanagement-app'
            service: 'web-application'

    - job_name: 'node-exporter'
      static_configs:
        - targets: ['localhost:9100']
          labels:
            instance: 'server-monitoring'
            service: 'system-metrics'

    - job_name: 'postgres-exporter'
      static_configs:
        - targets: ['localhost:9187']
          labels:
            instance: 'database-monitoring'
            service: 'postgres-metrics'

## Alertmanager Configuration
alertmanager:
  global:
    resolve_timeout: 5m
    smtp_smarthost: 'smtp.gmail.com:587'
    smtp_from: 'alerts@autoprojectmanagement.com'
    smtp_auth_username: 'alert-user'
    smtp_auth_password: '${SMTP_PASSWORD}'

  route:
    group_by: ['alertname', 'environment']
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 3h
    receiver: 'slack-notifications'

    routes:
      - match:
          severity: critical
        receiver: 'pagerduty-critical'
        repeat_interval: 30m

      - match:
          severity: warning
        receiver: 'email-notifications'

  receivers:
    - name: 'slack-notifications'
      slack_configs:
        - api_url: '${SLACK_WEBHOOK_URL}'
          channel: '#alerts'
          send_resolved: true
          title: '{{ .CommonAnnotations.summary }}'
          text: |-
            {{ range .Alerts }}
              *Alert:* {{ .Annotations.summary }}
              *Description:* {{ .Annotations.description }}
              *Severity:* {{ .Labels.severity }}
              *Instance:* {{ .Labels.instance }}
            {{ end }}

    - name: 'pagerduty-critical'
      pagerduty_configs:
        - service_key: '${PAGERDUTY_SERVICE_KEY}'
          description: '{{ .CommonAnnotations.summary }}'
          details:
            severity: '{{ .Labels.severity }}'
            instance: '{{ .Labels.instance }}'

    - name: 'email-notifications'
      email_configs:
        - to: 'devops@autoprojectmanagement.com'
          from: 'alerts@autoprojectmanagement.com'
          smarthost: 'smtp.gmail.com:587'
          auth_username: 'alert-user'
          auth_password: '${SMTP_PASSWORD}'
          require_tls: true

## Alert Rules
alert_rules:
  groups:
    - name: autoprojectmanagement
      rules:
        # High response time alert
        - alert: HighResponseTime
          expr: rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m]) > 0.5
          for: 5m
          labels:
            severity: critical
            environment: production
          annotations:
            summary: "High response time detected"
            description: "Average response time is above 500ms for 5 minutes"

        # High error rate alert
        - alert: HighErrorRate
          expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
          for: 5m
          labels:
            severity: critical
            environment: production
          annotations:
            summary: "High error rate detected"
            description: "Error rate is above 5% for 5 minutes"

        # Database connection issues
        - alert: DatabaseConnectionIssues
          expr: pg_up == 0
          for: 2m
          labels:
            severity: critical
            environment: production
          annotations:
            summary: "Database connection lost"
            description: "Database is not responding for 2 minutes"

        # High CPU usage
        - alert: HighCPUUsage
          expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
          for: 10m
          labels:
            severity: warning
            environment: production
          annotations:
            summary: "High CPU usage"
            description: "CPU usage is above 80% for 10 minutes"

        # High memory usage
        - alert: HighMemoryUsage
          expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
          for: 10m
          labels:
            severity: warning
            environment: production
          annotations:
            summary: "High memory usage"
            description: "Memory usage is above 85% for 10 minutes"

        # Disk space running out
        - alert: LowDiskSpace
          expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} * 100 < 10
          for: 5m
          labels:
            severity: warning
            environment: production
          annotations:
            summary: "Low disk space"
            description: "Disk space is below 10%"

## Grafana Dashboards
grafana:
  dashboards:
    - name: "Application Overview"
      description: "Overview of application performance and health"
      panels:
        - title: "Request Rate"
          type: "graph"
          query: "rate(http_requests_total[5m])"
          
        - title: "Response Time"
          type: "graph"
          query: "rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])"
          
        - title: "Error Rate"
          type: "graph"
          query: "rate(http_requests_total{status=~'5..'}[5m]) / rate(http_requests_total[5m])"
          
        - title: "Database Connections"
          type: "graph"
          query: "pg_stat_activity_count"

    - name: "System Metrics"
      description: "System-level metrics and resource usage"
      panels:
        - title: "CPU Usage"
          type: "graph"
          query: "100 - (avg by(instance) (rate(node_cpu_seconds_total{mode='idle'}[5m])) * 100)"
          
        - title: "Memory Usage"
          type: "graph"
          query: "(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100"
          
        - title: "Disk Usage"
          type: "graph"
          query: "(node_filesystem_size_bytes{mountpoint='/'} - node_filesystem_avail_bytes{mountpoint='/'}) / node_filesystem_size_bytes{mountpoint='/'} * 100"

## Docker Compose for Monitoring Stack
docker_compose_monitoring: |
  version: '3.8'
  services:
    prometheus:
      image: prom/prometheus:latest
      ports:
        - "9090:9090"
      volumes:
        - ./prometheus.yml:/etc/prometheus/prometheus.yml
        - prometheus_data:/prometheus
      command:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--web.console.libraries=/etc/prometheus/console_libraries'
        - '--web.console.templates=/etc/prometheus/console_templates'
        - '--storage.tsdb.retention.time=30d'

    grafana:
      image: grafana/grafana:latest
      ports:
        - "3000:3000"
      volumes:
        - grafana_data:/var/lib/grafana
        - ./grafana/provisioning:/etc/grafana/provisioning
      environment:
        - GF_SECURITY_ADMIN_PASSWORD=admin
      depends_on:
        - prometheus

    node-exporter:
      image: prom/node-exporter:latest
      ports:
        - "9100:9100"

    alertmanager:
      image: prom/alertmanager:latest
      ports:
        - "9093:9093"
      volumes:
        - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml

  volumes:
    prometheus_data:
    grafana_data:

## Setup Instructions
setup_instructions:
  - Install Docker and Docker Compose
  - Clone this repository
  - Copy this configuration to appropriate files:
    - prometheus.yml
    - alertmanager.yml
  - Set environment variables for sensitive data
  - Run: docker-compose -f docker-compose-monitoring.yml up -d
  - Access:
    - Prometheus: http://localhost:9090
    - Grafana: http://localhost:3000 (admin/admin)
    - Alertmanager: http://localhost:9093

## Environment Variables
environment_variables:
  - SMTP_PASSWORD: "SMTP server password for email alerts"
  - SLACK_WEBHOOK_URL: "Slack incoming webhook URL"
  - PAGERDUTY_SERVICE_KEY: "PagerDuty service integration key"

## Maintenance
maintenance:
  - Regularly check Prometheus storage retention
  - Monitor alertmanager configuration
  - Update Grafana dashboards as needed
  - Review and tune alert thresholds
  - Backup configuration files

## Version History
- v1.0: Initial monitoring configuration
- v1.1: Added alert rules and Grafana dashboards
- v1.2: Enhanced documentation and setup instructions
